#ì €ì¥ëœ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ì¶œë ¥
import os
from movie_review.Naver_NLP_Train import MAX_TOKENS
import matplotlib.pyplot as plt
import pickle
import numpy as np
from konlpy.tag import Okt
import re

PATH=r"movie_review/"
#PATH=r"./"
import tensorflow as tf
print(tf.__version__)
#ëª¨ë¸ìƒì„±
model = None
MAX_TOKENS=0
MAX_LEN=0
VOCAB=None
#ê°€ì¤‘ì¹˜ ì…‹íŒ…
#print(model.get_weights()[:5])
print("ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜ğŸ˜˜")
if os.path.exists(f"{PATH}config/nlp_model.keras"):
    configs = None
    with open(f"{PATH}config/config","rb") as fp:
        configs = pickle.load(fp)
    print(configs)
    MAX_TOKENS=configs["max_tokens"]
    MAX_LEN=configs["max_len"]
    print(configs)
    VOCAB = configs["vocab"]
    print(os.path.exists(f"{PATH}config/nlp_model.keras"))
    model=tf.keras.models.load_model(
        f"{PATH}config/nlp_model.keras")
    model.summary()
    plt.show()
    #ë ˆì´ì–´ ì´ë¦„ë„ ë™ì¼í•´ì•¼í•©ë‹ˆë‹¤.
    #model.load_weights(f"{PATH}config/naver_move_npl.weights.h5")
    #print(model.get_weights()[:5])
#ì‚¬ì „ì„¤ì •
tv = tf.keras.layers.TextVectorization(
    max_tokens=MAX_TOKENS,#ì‚¬ì „í¬ê¸°
    output_mode='int',
    pad_to_max_tokens=True,
    output_sequence_length=MAX_LEN,#ì „ì²´ë¬¸ì¥ì˜ ê¸¸ì´, ìë™íŒ¨ë”©ê³¼ ìŠ¤í”¼ë¦¿
)
tv.set_vocabulary(VOCAB)
def get_userData(user_data):# ì´ ì˜í™”ëŠ” ë„ˆë¬´ ì¬ë°Œì–´
    # ì •ê·œì‹ ì „í™˜, ë¶ˆìš©ì–´ì²˜ë¦¬/í˜•íƒœì†Œë¶„ë¥˜, ìˆ«ìë³€í™˜(Tokenizer-vocab)
    reg_han = r"[^\sã„±-ã…ê°€-í£]"
    user_data = re.sub(reg_han,"",user_data)
    #user_data.replace(to_replace=reg_han, regex=True, inplace=True, value="")
    if not user_data :
        print("ì¢€ ë” ëª…í™•í•œ ì…ë ¥ì„ í•´ì£¼ì„¸ìš”")
    stopword = ["ì—ì„œ", "ì€", "ëŠ”", "ì´", "ê°€", "ì´ë‹¤", "í•˜ë‹¤", "ë“¤", "ì¢€", "ê±", "ë„", "ìš”",
                "í ", "ì—ê²Œ", "ë‚˜ë‹¤", "ë°", "ìˆë‹¤", "í•´ë„", "ì—", "ì˜", "ì„", "ë¥¼", "ë‹¤", "í•œ",
                "ê²ƒ", "ë‚´", "ê·¸", "ë‚˜"]
    # ë‚˜ì¤‘ì— ë‹¨ì–´ ì¶œí˜„ íšŸìˆ˜ì— ë”°ë¼ ì˜ë¯¸ì—†ëŠ” ë‹¨ì–´ëŠ” ì¶”ê°€í•˜ì—¬ ë‹¤ì‹œ ì œê±°ë¥¼ í•˜ëŠ”ê²Œ ì¢‹ë‹¤.
    print("í•œê¸€ í˜•íƒœì†Œ ë¶„ë¦¬ ì‹¤í–‰")
    okt = Okt()
    x_user = []
    token_word = okt.morphs(user_data, stem=True)  # ë¦¬í„´ê°’ : ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
    x_user.append(" ".join([w for w in token_word if not w in stopword]))
    x_user = np.array(x_user)
    return x_user
def vocab_process(x_user):
    global tv
    return tv(x_user)
def predict_userdata(x_user):
    global model
    return model.predict(x_user)
if __name__=="__main__":
    x_user = get_userData("ì˜í™” ë„ˆë¬´ë„ˆë¬´ ì¬ë°Œë„¤ ê°œë‚˜ ì¤˜ë²„ë ¤")
    x_user = vocab_process(x_user)
    print(predict_userdata(x_user))

